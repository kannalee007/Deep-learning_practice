{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88b14d0a-aadc-430a-ab25-dd4e6b22f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd0a93e7-b422-4363-bf46-df1be6444014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train_full,y_train_full), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "393fefbb-2e96-4d9a-b0c2-2b32c55cdfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, x_train = x_train_full[:5000],x_train_full[5000:]/255\n",
    "y_val, y_train = y_train_full[:5000],y_train_full[5000:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229df3d1-985c-4bef-9a58-fcfb4e2da9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  44, 127,\n",
       "        182, 185, 161, 120,  55,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 198, 251, 255,\n",
       "        251, 249, 247, 255, 252, 214, 100,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   2,   0,   0, 233, 252, 237, 239,\n",
       "        234, 237, 235, 237, 237, 254, 227,   0,   0,   0,   0,   1,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   0,  16, 210, 225, 215, 175,\n",
       "        217, 216, 193, 196, 226, 221, 209,  50,   0,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   2,   0,   0, 199, 229, 232, 230, 245, 204,\n",
       "        219, 253, 245, 207, 194, 223, 231, 236, 235,   0,   0,   3,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0, 137, 235, 204, 209, 201, 209, 234,\n",
       "        190, 234, 218, 215, 238, 239, 204, 189, 224, 154,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 194, 201, 200, 209, 202, 193, 205,\n",
       "        194, 183, 218, 231, 197, 172, 181, 193, 205, 199,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3, 212, 203, 188, 189, 196, 198, 198,\n",
       "        201, 196, 217, 179, 167, 183, 217, 197, 202, 219,  30,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  34, 225, 200, 194, 190, 188, 192, 196,\n",
       "        192, 170, 202, 190, 201, 195, 200, 201, 209, 227,  50,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  68, 225, 210, 211, 198, 192, 196, 204,\n",
       "        196, 181, 212, 197, 195, 192, 206, 220, 210, 229,  93,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 111, 223, 227, 253, 209, 196, 204, 211,\n",
       "        206, 183, 216, 206, 210, 203, 215, 244, 224, 227, 150,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 139, 225, 224, 255, 202, 206, 212, 209,\n",
       "        211, 190, 213, 202, 207, 206, 222, 255, 230, 220, 190,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 180, 226, 224, 255, 199, 204, 207, 214,\n",
       "        214, 190, 216, 206, 203, 205, 219, 243, 224, 214, 234,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 225, 223, 228, 254, 209, 206, 208, 213,\n",
       "        210, 191, 215, 207, 204, 208, 211, 249, 226, 214, 255,  38,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 250, 232, 240, 239, 211, 203, 209, 205,\n",
       "        211, 197, 215, 208, 208, 214, 213, 239, 231, 219, 255,  81,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 248, 236, 247, 240, 203, 200, 208, 206,\n",
       "        214, 193, 213, 212, 208, 212, 211, 243, 242, 225, 254,  66,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 247, 230, 252, 226, 199, 211, 202, 211,\n",
       "        213, 182, 213, 212, 206, 202, 219, 207, 247, 222, 237, 104,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  10, 244, 219, 250, 205, 199, 209, 202, 209,\n",
       "        211, 189, 214, 206, 210, 200, 212, 154, 240, 208, 219, 140,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  21, 255, 222, 238, 184, 210, 192, 206, 209,\n",
       "        210, 189, 213, 211, 209, 192, 228, 155, 226, 238, 241, 166,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  37, 245, 226, 241, 150, 197, 189, 204, 209,\n",
       "        210, 183, 213, 213, 201, 184, 215, 146, 216, 236, 225, 154,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  58, 239, 227, 255, 158, 193, 195, 204, 209,\n",
       "        213, 180, 207, 217, 199, 194, 211, 158, 219, 236, 216, 151,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  68, 233, 226, 243, 139, 200, 193, 205, 210,\n",
       "        208, 180, 205, 212, 203, 196, 216, 157, 179, 255, 216, 155,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  81, 225, 224, 211, 138, 219, 185, 201, 213,\n",
       "        207, 197, 226, 212, 200, 190, 215, 183,  90, 255, 211, 147,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  91, 210, 230, 158, 114, 205, 187, 208, 209,\n",
       "        206, 193, 210, 211, 204, 195, 204, 181,  23, 255, 213, 158,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  87, 205, 232, 109, 164, 255, 214, 224, 222,\n",
       "        210, 197, 214, 225, 222, 211, 220, 217,   0, 234, 216, 169,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  92, 213, 232, 146,   5, 134, 151, 162, 170,\n",
       "        183, 182, 164, 166, 178, 162, 156,  98,   0, 240, 225, 210,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  43, 164, 206, 141,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0, 127, 125,  76,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6e69cda-1d94-4f51-9a84-dc8d1591f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential() # empty model created\n",
    "model.add(keras.layers.Flatten(input_shape = [28,28])) #adding the input size (as our data set is 28*28 pixels)\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))#hidden layer\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))#hidden layer\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax')) #kind of output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "233d98ea-862b-4dbd-b8b3-1c953ae54936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d927a08b-2608-400c-8ad3-da04eb7ee9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten_6, built=True>,\n",
       " <Dense name=dense_32, built=True>,\n",
       " <Dense name=dense_33, built=True>,\n",
       " <Dense name=dense_34, built=True>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54c961a9-78b1-465f-a918-523590352b2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument(s) not recognized: {'lr': 0.01}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer=\u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/keras/src/optimizers/sgd.py:60\u001b[39m, in \u001b[36mSGD.__init__\u001b[39m\u001b[34m(self, learning_rate, momentum, nesterov, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     45\u001b[39m     learning_rate=\u001b[32m0.01\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     **kwargs,\n\u001b[32m     59\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclipvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m        \u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mglobal_clipnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_ema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mema_momentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m        \u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mema_overwrite_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_scale_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_scale_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(momentum, \u001b[38;5;28mfloat\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m momentum < \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m momentum > \u001b[32m1\u001b[39m:\n\u001b[32m     75\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`momentum` must be a float between [0, 1].\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/keras/src/backend/tensorflow/optimizer.py:21\u001b[39m, in \u001b[36mTFOptimizer.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mself\u001b[39m._distribution_strategy = tf.distribute.get_strategy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/keras/src/optimizers/base_optimizer.py:90\u001b[39m, in \u001b[36mBaseOptimizer.__init__\u001b[39m\u001b[34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m     warnings.warn(\n\u001b[32m     87\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mArgument `decay` is no longer supported and will be ignored.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m     )\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mArgument(s) not recognized: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     93\u001b[39m     name = auto_name(\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: Argument(s) not recognized: {'lr': 0.01}"
     ]
    }
   ],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy, optimizer=\"sgd\", metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6343a-4620-429b-9060-ec467204e17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
